{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import os\n",
    "import pickle\n",
    "import math\n",
    "import time\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils import data\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('embeddings/bag_of_words_train.pickle', 'rb') as f:\n",
    "    transcript_embeddings = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34586\n"
     ]
    }
   ],
   "source": [
    "transcript_qna = []\n",
    "for i in range(len(transcript_embeddings)):\n",
    "    transcript_qna.append(transcript_embeddings[i][1])\n",
    "qna_pairs = []\n",
    "\n",
    "for i in range(len(transcript_qna)):\n",
    "    counter = 0\n",
    "    while(True):\n",
    "        if counter > len(transcript_qna[i]) - 2: break\n",
    "        qna_pairs.append((transcript_qna[i][counter][0].toarray()[0], transcript_qna[i][counter+1][0].toarray()[0]))\n",
    "        counter+=2\n",
    "print(len(qna_pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QADataset(Dataset):\n",
    "    \"\"\"Face Landmarks dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, qna_list):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (string): Path to the csv file with annotations.\n",
    "            root_dir (string): Directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        self.qna = qna_list\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.qna)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.qna[idx][0], self.qna[idx][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SiameseNetwork(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super().__init__()\n",
    "        self.L1 = nn.Linear(input_size, hidden_size)\n",
    "        nn.init.kaiming_normal_(self.L1.weight)\n",
    "        self.L2 = nn.Linear(hidden_size, output_size)\n",
    "        nn.init.kaiming_normal_(self.L2.weight)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x_L1 = self.L1(x)\n",
    "        x_relu = torch.nn.functional.relu(x_L1)\n",
    "        x_L2 = self.L2(x_relu)  \n",
    "        return x_L2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_per_epoch = []\n",
    "cos_sim_per_epoch = []\n",
    "def train(network, train_data, dev_data, output_path, batch_size=16, n_epochs=1, lr=0.001):\n",
    "    \"\"\" Train the Siamese Network.\n",
    "\n",
    "    @param network (network): SiameseNetwork\n",
    "    @param train_data ():\n",
    "    @param dev_data ():\n",
    "    @param output_path (str): Path to which model weights and results are written.\n",
    "    @param batch_size (int): Number of examples in a single batch\n",
    "    @param n_epochs (int): Number of training epochs\n",
    "    @param lr (float): Learning rate\n",
    "    \"\"\"\n",
    "    best_dev_cos_sim = 0\n",
    "    optimizer = optim.Adam(network.parameters(),lr = lr)\n",
    "    loss_func = nn.CosineEmbeddingLoss()\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        print(\"Epoch {:} out of {:}\".format(epoch+2, n_epochs+2))\n",
    "        dev_cos_sim = train_for_epoch(network, train_data, dev_data, optimizer, loss_func, batch_size)\n",
    "        best_dev_cos_sim = dev_cos_sim\n",
    "        print(\"Saving model for epoch: \", epoch+2)\n",
    "        \n",
    "        torch.save(network.state_dict(), output_path + \"_\" + str(epoch+2))\n",
    "        print(\"\")\n",
    "\n",
    "\n",
    "def train_for_epoch(network, train_data, dev_data, optimizer, loss_func, batch_size):\n",
    "    \"\"\" Train network for single epoch.\n",
    "\n",
    "    @param network (Network): SiameseNetwork\n",
    "    @param train_data ():\n",
    "    @param dev_data ():\n",
    "    @param optimizer (nn.Optimizer): Adam Optimizer\n",
    "    @param loss_func (cos_sim): Cosine Similarity Loss Function\n",
    "    @param lr (float): learning rate\n",
    "\n",
    "    @return dev_cos_sim (float): Cosine Similarity scores for dev data\n",
    "    \"\"\"\n",
    "\n",
    "    n_minibatches = math.ceil(len(train_data) / batch_size)\n",
    "    loss_meter = AverageMeter()\n",
    "    train_generator = data.DataLoader(train_data, batch_size = batch_size)\n",
    "    dev_generator = data.DataLoader(dev_data, batch_size = batch_size)\n",
    "    \n",
    "    with tqdm(total=(n_minibatches)) as prog:\n",
    "        for questions, answers in train_generator:\n",
    "            optimizer.zero_grad()   # remove any baggage in the optimizer\n",
    "            loss = 0. # store loss for this batch here\n",
    "            train_q = questions.float()\n",
    "            train_a = answers.float()\n",
    "            output_q = network.forward(train_q)\n",
    "            output_a = network.forward(train_a)\n",
    "            \n",
    "            loss = loss_func(output_q, output_a, torch.tensor(1, dtype=torch.float))\n",
    "            for a_index in range(answers.shape[0]):\n",
    "                q_index = np.random.choice(list(range(a_index)) + list(range(a_index + 1, output_a.shape[0])))  \n",
    "                loss += loss_func(torch.reshape(output_q[q_index], (1, output_q[q_index].shape[0])), \n",
    "                                          torch.reshape(output_a[a_index], (1, output_a[a_index].shape[0])),torch.tensor(-1, dtype=torch.float)) \n",
    "                \n",
    "            loss_per_epoch.append(loss)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            ### END YOUR CODE\n",
    "            prog.update(1)\n",
    "            loss_meter.update(loss.item())\n",
    "\n",
    "    print (\"Average Train Loss: {}\".format(loss_meter.avg))\n",
    "    print(\"Evaluating on cosine similarity dev set\",)\n",
    "    with torch.set_grad_enabled(False):\n",
    "        cosine_sim = 0.\n",
    "        for questions, answers in dev_generator:\n",
    "            dev_q = questions.float()\n",
    "            dev_a = answers.float()\n",
    "            output_q = network.forward(dev_q)\n",
    "            output_a = network.forward(dev_a)\n",
    "            cosine_sim += torch.sum(torch.nn.functional.cosine_similarity(output_q, output_a)).item()\n",
    "    \n",
    "    \n",
    "    avg_cosine_sim = cosine_sim / len(dev_data)\n",
    "    cos_sim_per_epoch.append(avg_cosine_sim)\n",
    "    print(\"- dev cosine similarity: {:.2f}\".format(avg_cosine_sim))\n",
    "    return avg_cosine_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "INITIALIZING\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1730 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "took 0.41 seconds\n",
      "\n",
      "================================================================================\n",
      "TRAINING\n",
      "================================================================================\n",
      "Epoch 2 out of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1730/1730 [10:30<00:00,  3.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Train Loss: 1.3333989169556282\n",
      "Evaluating on cosine similarity dev set\n",
      "- dev cosine similarity: 0.02\n",
      "Saving model for epoch:  2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "input_size = len(qna_pairs[0][0])\n",
    "hidden_dim = 256 #1000\n",
    "output_dim = 128 #768\n",
    "\n",
    "print(80 * \"=\")\n",
    "print(\"INITIALIZING\")\n",
    "print(80 * \"=\")\n",
    "\n",
    "test_val_split = int(len(qna_pairs)*0.8)\n",
    "train_data = QADataset(qna_pairs[0:test_val_split])\n",
    "dev_data = QADataset(qna_pairs[test_val_split:])\n",
    "\n",
    "start = time.time()\n",
    "network =  SiameseNetwork(input_size, hidden_dim, output_dim)  \n",
    "network.load_state_dict(torch.load(\"./results/model.weights_1\"))\n",
    "print(\"took {:.2f} seconds\\n\".format(time.time() - start))\n",
    "\n",
    "print(80 * \"=\")\n",
    "print(\"TRAINING\")\n",
    "print(80 * \"=\")\n",
    "output_dir = \"results/\"\n",
    "output_path = output_dir + \"model.weights\"\n",
    "\n",
    "if not os.path.exists(output_dir): os.makedirs(output_dir)\n",
    "\n",
    "train(network, train_data, dev_data, output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('embeddings/bag_of_words_test.pickle', 'rb') as f:\n",
    "    test_embeddings = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[<1x65245 sparse matrix of type '<class 'numpy.int64'>'\n",
      "\twith 40 stored elements in Compressed Sparse Row format>, <1x65245 sparse matrix of type '<class 'numpy.int64'>'\n",
      "\twith 52 stored elements in Compressed Sparse Row format>, <1x65245 sparse matrix of type '<class 'numpy.int64'>'\n",
      "\twith 26 stored elements in Compressed Sparse Row format>, <1x65245 sparse matrix of type '<class 'numpy.int64'>'\n",
      "\twith 61 stored elements in Compressed Sparse Row format>, <1x65245 sparse matrix of type '<class 'numpy.int64'>'\n",
      "\twith 53 stored elements in Compressed Sparse Row format>, <1x65245 sparse matrix of type '<class 'numpy.int64'>'\n",
      "\twith 57 stored elements in Compressed Sparse Row format>, <1x65245 sparse matrix of type '<class 'numpy.int64'>'\n",
      "\twith 50 stored elements in Compressed Sparse Row format>, <1x65245 sparse matrix of type '<class 'numpy.int64'>'\n",
      "\twith 39 stored elements in Compressed Sparse Row format>, <1x65245 sparse matrix of type '<class 'numpy.int64'>'\n",
      "\twith 47 stored elements in Compressed Sparse Row format>, <1x65245 sparse matrix of type '<class 'numpy.int64'>'\n",
      "\twith 57 stored elements in Compressed Sparse Row format>, <1x65245 sparse matrix of type '<class 'numpy.int64'>'\n",
      "\twith 58 stored elements in Compressed Sparse Row format>, <1x65245 sparse matrix of type '<class 'numpy.int64'>'\n",
      "\twith 53 stored elements in Compressed Sparse Row format>, <1x65245 sparse matrix of type '<class 'numpy.int64'>'\n",
      "\twith 55 stored elements in Compressed Sparse Row format>, <1x65245 sparse matrix of type '<class 'numpy.int64'>'\n",
      "\twith 54 stored elements in Compressed Sparse Row format>, <1x65245 sparse matrix of type '<class 'numpy.int64'>'\n",
      "\twith 54 stored elements in Compressed Sparse Row format>, <1x65245 sparse matrix of type '<class 'numpy.int64'>'\n",
      "\twith 60 stored elements in Compressed Sparse Row format>, <1x65245 sparse matrix of type '<class 'numpy.int64'>'\n",
      "\twith 59 stored elements in Compressed Sparse Row format>, <1x65245 sparse matrix of type '<class 'numpy.int64'>'\n",
      "\twith 31 stored elements in Compressed Sparse Row format>, <1x65245 sparse matrix of type '<class 'numpy.int64'>'\n",
      "\twith 50 stored elements in Compressed Sparse Row format>, <1x65245 sparse matrix of type '<class 'numpy.int64'>'\n",
      "\twith 33 stored elements in Compressed Sparse Row format>, <1x65245 sparse matrix of type '<class 'numpy.int64'>'\n",
      "\twith 43 stored elements in Compressed Sparse Row format>, <1x65245 sparse matrix of type '<class 'numpy.int64'>'\n",
      "\twith 44 stored elements in Compressed Sparse Row format>, <1x65245 sparse matrix of type '<class 'numpy.int64'>'\n",
      "\twith 50 stored elements in Compressed Sparse Row format>, <1x65245 sparse matrix of type '<class 'numpy.int64'>'\n",
      "\twith 48 stored elements in Compressed Sparse Row format>, <1x65245 sparse matrix of type '<class 'numpy.int64'>'\n",
      "\twith 55 stored elements in Compressed Sparse Row format>, <1x65245 sparse matrix of type '<class 'numpy.int64'>'\n",
      "\twith 45 stored elements in Compressed Sparse Row format>, <1x65245 sparse matrix of type '<class 'numpy.int64'>'\n",
      "\twith 52 stored elements in Compressed Sparse Row format>, <1x65245 sparse matrix of type '<class 'numpy.int64'>'\n",
      "\twith 52 stored elements in Compressed Sparse Row format>, <1x65245 sparse matrix of type '<class 'numpy.int64'>'\n",
      "\twith 48 stored elements in Compressed Sparse Row format>, <1x65245 sparse matrix of type '<class 'numpy.int64'>'\n",
      "\twith 51 stored elements in Compressed Sparse Row format>, <1x65245 sparse matrix of type '<class 'numpy.int64'>'\n",
      "\twith 53 stored elements in Compressed Sparse Row format>, <1x65245 sparse matrix of type '<class 'numpy.int64'>'\n",
      "\twith 57 stored elements in Compressed Sparse Row format>, <1x65245 sparse matrix of type '<class 'numpy.int64'>'\n",
      "\twith 50 stored elements in Compressed Sparse Row format>, <1x65245 sparse matrix of type '<class 'numpy.int64'>'\n",
      "\twith 50 stored elements in Compressed Sparse Row format>, <1x65245 sparse matrix of type '<class 'numpy.int64'>'\n",
      "\twith 56 stored elements in Compressed Sparse Row format>, <1x65245 sparse matrix of type '<class 'numpy.int64'>'\n",
      "\twith 11 stored elements in Compressed Sparse Row format>], [(<1x65245 sparse matrix of type '<class 'numpy.int64'>'\n",
      "\twith 11 stored elements in Compressed Sparse Row format>, 0), (<1x65245 sparse matrix of type '<class 'numpy.int64'>'\n",
      "\twith 3 stored elements in Compressed Sparse Row format>, 1), (<1x65245 sparse matrix of type '<class 'numpy.int64'>'\n",
      "\twith 26 stored elements in Compressed Sparse Row format>, 0), (<1x65245 sparse matrix of type '<class 'numpy.int64'>'\n",
      "\twith 73 stored elements in Compressed Sparse Row format>, 1), (<1x65245 sparse matrix of type '<class 'numpy.int64'>'\n",
      "\twith 19 stored elements in Compressed Sparse Row format>, 0), (<1x65245 sparse matrix of type '<class 'numpy.int64'>'\n",
      "\twith 47 stored elements in Compressed Sparse Row format>, 1), (<1x65245 sparse matrix of type '<class 'numpy.int64'>'\n",
      "\twith 34 stored elements in Compressed Sparse Row format>, 0), (<1x65245 sparse matrix of type '<class 'numpy.int64'>'\n",
      "\twith 67 stored elements in Compressed Sparse Row format>, 1), (<1x65245 sparse matrix of type '<class 'numpy.int64'>'\n",
      "\twith 63 stored elements in Compressed Sparse Row format>, 0), (<1x65245 sparse matrix of type '<class 'numpy.int64'>'\n",
      "\twith 130 stored elements in Compressed Sparse Row format>, 1), (<1x65245 sparse matrix of type '<class 'numpy.int64'>'\n",
      "\twith 47 stored elements in Compressed Sparse Row format>, 0), (<1x65245 sparse matrix of type '<class 'numpy.int64'>'\n",
      "\twith 132 stored elements in Compressed Sparse Row format>, 1), (<1x65245 sparse matrix of type '<class 'numpy.int64'>'\n",
      "\twith 23 stored elements in Compressed Sparse Row format>, 0), (<1x65245 sparse matrix of type '<class 'numpy.int64'>'\n",
      "\twith 34 stored elements in Compressed Sparse Row format>, 1), (<1x65245 sparse matrix of type '<class 'numpy.int64'>'\n",
      "\twith 8 stored elements in Compressed Sparse Row format>, 0), (<1x65245 sparse matrix of type '<class 'numpy.int64'>'\n",
      "\twith 16 stored elements in Compressed Sparse Row format>, 1), (<1x65245 sparse matrix of type '<class 'numpy.int64'>'\n",
      "\twith 10 stored elements in Compressed Sparse Row format>, 0), (<1x65245 sparse matrix of type '<class 'numpy.int64'>'\n",
      "\twith 3 stored elements in Compressed Sparse Row format>, 1), (<1x65245 sparse matrix of type '<class 'numpy.int64'>'\n",
      "\twith 12 stored elements in Compressed Sparse Row format>, 0), (<1x65245 sparse matrix of type '<class 'numpy.int64'>'\n",
      "\twith 2 stored elements in Compressed Sparse Row format>, 1), (<1x65245 sparse matrix of type '<class 'numpy.int64'>'\n",
      "\twith 27 stored elements in Compressed Sparse Row format>, 0), (<1x65245 sparse matrix of type '<class 'numpy.int64'>'\n",
      "\twith 23 stored elements in Compressed Sparse Row format>, 1), (<1x65245 sparse matrix of type '<class 'numpy.int64'>'\n",
      "\twith 15 stored elements in Compressed Sparse Row format>, 0), (<1x65245 sparse matrix of type '<class 'numpy.int64'>'\n",
      "\twith 6 stored elements in Compressed Sparse Row format>, 1), (<1x65245 sparse matrix of type '<class 'numpy.int64'>'\n",
      "\twith 8 stored elements in Compressed Sparse Row format>, 0), (<1x65245 sparse matrix of type '<class 'numpy.int64'>'\n",
      "\twith 14 stored elements in Compressed Sparse Row format>, 1), (<1x65245 sparse matrix of type '<class 'numpy.int64'>'\n",
      "\twith 50 stored elements in Compressed Sparse Row format>, 0), (<1x65245 sparse matrix of type '<class 'numpy.int64'>'\n",
      "\twith 40 stored elements in Compressed Sparse Row format>, 1), (<1x65245 sparse matrix of type '<class 'numpy.int64'>'\n",
      "\twith 28 stored elements in Compressed Sparse Row format>, 0), (<1x65245 sparse matrix of type '<class 'numpy.int64'>'\n",
      "\twith 38 stored elements in Compressed Sparse Row format>, 1), (<1x65245 sparse matrix of type '<class 'numpy.int64'>'\n",
      "\twith 33 stored elements in Compressed Sparse Row format>, 0), (<1x65245 sparse matrix of type '<class 'numpy.int64'>'\n",
      "\twith 43 stored elements in Compressed Sparse Row format>, 1), (<1x65245 sparse matrix of type '<class 'numpy.int64'>'\n",
      "\twith 16 stored elements in Compressed Sparse Row format>, 0), (<1x65245 sparse matrix of type '<class 'numpy.int64'>'\n",
      "\twith 44 stored elements in Compressed Sparse Row format>, 1), (<1x65245 sparse matrix of type '<class 'numpy.int64'>'\n",
      "\twith 19 stored elements in Compressed Sparse Row format>, 0), (<1x65245 sparse matrix of type '<class 'numpy.int64'>'\n",
      "\twith 2 stored elements in Compressed Sparse Row format>, 1), (<1x65245 sparse matrix of type '<class 'numpy.int64'>'\n",
      "\twith 31 stored elements in Compressed Sparse Row format>, 0), (<1x65245 sparse matrix of type '<class 'numpy.int64'>'\n",
      "\twith 103 stored elements in Compressed Sparse Row format>, 1), (<1x65245 sparse matrix of type '<class 'numpy.int64'>'\n",
      "\twith 18 stored elements in Compressed Sparse Row format>, 0), (<1x65245 sparse matrix of type '<class 'numpy.int64'>'\n",
      "\twith 23 stored elements in Compressed Sparse Row format>, 1), (<1x65245 sparse matrix of type '<class 'numpy.int64'>'\n",
      "\twith 30 stored elements in Compressed Sparse Row format>, 0), (<1x65245 sparse matrix of type '<class 'numpy.int64'>'\n",
      "\twith 39 stored elements in Compressed Sparse Row format>, 1), (<1x65245 sparse matrix of type '<class 'numpy.int64'>'\n",
      "\twith 29 stored elements in Compressed Sparse Row format>, 0), (<1x65245 sparse matrix of type '<class 'numpy.int64'>'\n",
      "\twith 88 stored elements in Compressed Sparse Row format>, 1), (<1x65245 sparse matrix of type '<class 'numpy.int64'>'\n",
      "\twith 49 stored elements in Compressed Sparse Row format>, 0), (<1x65245 sparse matrix of type '<class 'numpy.int64'>'\n",
      "\twith 142 stored elements in Compressed Sparse Row format>, 1), (<1x65245 sparse matrix of type '<class 'numpy.int64'>'\n",
      "\twith 3 stored elements in Compressed Sparse Row format>, 0)]]\n"
     ]
    }
   ],
   "source": [
    "print(test_embeddings[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "network =  SiameseNetwork(input_size, hidden_dim, output_dim)  \n",
    "network.load_state_dict(torch.load(\"./results/model.weights_2\"))\n",
    "embeded_transcripts = []\n",
    "\n",
    "with torch.set_grad_enabled(False):\n",
    "    for i in range(len(test_embeddings)):\n",
    "        new_transcript, embed_statement, embed_qna = [], [], []\n",
    "\n",
    "        statement =  test_embeddings[i][0]\n",
    "        for j in range(len(statement)):\n",
    "            output = network.forward(torch.tensor(statement[j].toarray(), dtype=torch.float32))\n",
    "            embed_statement.append(output.numpy())  \n",
    "        new_transcript.append(embed_statement)\n",
    "\n",
    "        qna = test_embeddings[i][1]\n",
    "        for j in range(len(qna)): \n",
    "            output = network.forward(torch.tensor(qna[j][0].toarray(), dtype=torch.float32))\n",
    "            embed_qna.append((output.numpy(), qna[j][1]))  \n",
    "        new_transcript.append(embed_qna)\n",
    "        embeded_transcripts.append(new_transcript)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('embeddings/siameseBOW_epoch3.pickle', 'wb') as f:\n",
    "    pickle.dump(embeded_transcripts, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
